\documentclass[11pt]{article}
\usepackage{amsmath,amssymb,amsthm,epsf,
graphics,enumerate,fancyhdr,marvosym,cancel}
\usepackage[letterpaper, margin=0.9in]{geometry}
\usepackage[scr=boondoxo]{mathalpha}

% ordered lists have letters instead of numbers
\renewcommand\theenumi{\alph{enumi}}
\renewcommand\labelenumi{(\theenumi)}

% subsections have letters instead of numbers
\renewcommand{\thesubsection}{\thesection (\alph{subsection})}

% use hyperref for links but don't draw the ugly boxes around links
\usepackage[hidelinks]{hyperref}

% command to create underlined link to outside websites
\newcommand{\hrefunderline}[2]{\underline{\href{#1}{#2}}}

% font to use for collections
\newcommand{\col}[1]{\mathscr{#1}}
% font to use for random variables
\newcommand{\rv}[1]{\mathsf{#1}}
% the probability metric
\newcommand{\p}{\mathbb{P}}
% expectation value
\newcommand{\ex}{\mathbb{E}}
% characteristic functions
\newcommand{\charf}[1]{\mathbf{1}_{#1}}
% the Borell sigma algebra on the reals
\newcommand{\bor}{\col{B}}
% power sets
\newcommand{\pset}[1]{P\left(#1\right)}
% command to emphasize the name of something defined
\newcommand{\defname}[1]{\underline{#1}}
% almost sure convergence
\newcommand{\asto}{\xrightarrow{\text{a.s.}}}
% convergence in probability
\newcommand{\pto}{\xrightarrow{\p}}
\newcommand{\disto}{\xrightarrow{\text{dist}}}


% symbols for common sets
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\FF}{\mathbb{F}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\CC}{\mathbb{C}}

% for congruences
\newcommand{\mmod}[1]{\;(\operatorname{mod} {#1})}

% new theorem style with boldface title and italic content
\newtheoremstyle{step}%            % Name
  {}%                                     % Space above
  {}%                                     % Space below
  {\itshape}%                           % Body font
  {}%                                     % Indent amount
  {\itshape}%                          % Theorem head font
  {:}%                                    % Punctuation after theorem head
  { }%                                    % Space after theorem head, ' ', or \newline
  {}%                                     % Theorem head spec (can be left empty, meaning `normal')

% new theorem style for a gap in the notes
\newtheoremstyle{gap}%            % Name
  {}%                                     % Space above
  {}%                                     % Space below
  {\itshape}%                           % Body font
  {}%                                     % Indent amount
  {\itshape}%                          % Theorem head font
  {!!!}%                                    % Punctuation after theorem head
  {    }%                                    % Space after theorem head, ' ', or \newline
  {}%                                     % Theorem head spec (can be left empty, meaning `normal')

\theoremstyle{theorem}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{notation}[theorem]{Notation}

\theoremstyle{remark}
\newtheorem{example}[theorem]{Example}
\newtheorem*{remark}{Remark}

\theoremstyle{step}
\newtheorem{step}{Step}[subsection]
\renewcommand{\thestep}{\arabic{step}}

\theoremstyle{gap}
\newtheorem*{gap}{Gap}

\begin{document}

\title{Probability Notes}
\author{Duncan MacIntyre}
\date{\today}
\maketitle
\tableofcontents
\bigskip
\newpage

\section{Some measure theory}

\begin{definition}
Let \(\Omega\) be a set. A \defname{topology} on \(\Omega\) is a collection \(\col{A} \subset \pset{\Omega}\) that is closed under unions and finite intersections with \(\Omega, \emptyset \in \col{A}\). For \(E \subset \Omega\), if \(E \in \col{A}\), we call \(E\) open, and if \(E^C \in \col{A}\), we call \(E\) closed.
\end{definition}

For example, if \((X, d)\) is a metric space, \(\col{A} = \left\{E | E = \cup_i N_{r_i} \left(x_i\right)\right\}\) is a topology on \(X\).

\begin{gap} The example should be proven.\end{gap}

\begin{definition}
Let \(\Omega\) be a set and \(\col{S} \subset \pset{\Omega}\). Then the \defname{topology generated by} \(\col{S}\) is
\[\col{A} = \left\{E \subset \Omega | E \text{ is a union of finite intersections of sets in } \col{S}.\right\}\]
\end{definition}

\begin{gap} The definition should be more explicit.\end{gap}

\begin{gap} Examples and Furstenberg's theorem should be added here \end{gap}

\begin{definition}
Let \(\Omega\) be a set. An \defname{algebra} is a collection \(\col{A} \subset \pset{\Omega}\) that is closed under finite unions and compliments with \(\Omega \in \col{A}\). If an algebra is also closed under countable unions, we call it a \defname{\(\sigma\)-algebra}.
\end{definition}

\begin{theorem}
Algebras are closed under finite intersections and \(\sigma\)-algebras are closed under countable intersections.
\end{theorem}

\begin{proof}
Let \(\col{A}\) be an algebra and let \(A_1, \ldots, A_n \in \col{A}\). Then \(A_1^C, \ldots, A_n^C \in \col{A}\), so \(\left(\cap_{i=1}^n A_i\right)^C = \cup_{i=1}^n A_i^C \in \col{A}\), so \(\cap_{i=1}^n A_i \in \col{A}\). The proof for \(\sigma\)-algebras is similar.
\end{proof}

\begin{definition}
Let \(\col{f}\) be a \(\sigma\)-algebra on a set \(\Omega\). A \defname{measure} on \(\col{f}\) is a function \(\mu:\col{f} \to [0, \infty]\) such that \(\mu(\emptyset) = 0\) and for all disjoint \(\left(A_i\right)_{i\in \NN} \in \col{f}\) we have \(\mu\left(\cup_i A_i\right) = \sum_i \mu\left(A_i\right)\). We call \((\Omega, \col{f}, \mu)\) a \defname{measure space}.
\end{definition}

\begin{gap}
Add examples of measures and probability measures.
\end{gap}

\begin{theorem}\label{thm.intersection-algebras}
An intersection of \(\sigma\)-algebras is also a \(\sigma\)-algebra.
\end{theorem}

\begin{proof}
Let \((\col{A}_i)\) be uncountably many \(\sigma\)-algebras. Let \(A \in \cap \col{A}_i\). Then \(A^C \in \col{A}_i\) for all \(\col{A}_i\), so \(A^C \in \cap \col{A}_i\). Similarly, let \((A_j)_{j \in \NN} \in \cap \col{A}_i\). Then \(\cup_j A_j \in \col{A_i}\) for all \(\col{A}_i\), so \(\cup_j A_j \in \cap \col{A_i}\).
\end{proof}

Theorem \ref{thm.intersection-algebras} motivates the following definition.

\begin{definition}
Let \(\col{A} \subset \Omega\). The \defname{\(\sigma\)-algebra generated by \(\col{A}\)} is the intersection of all \(\sigma\)-algebras that contain \(\col{A}\). We denote it by \(\sigma(\col{A})\).
\end{definition}

We can think of \(\sigma(\col{A})\) as the smallest \(\sigma\)-algebra containing \(\col{A}\).

\begin{notation}
A Borel \(\sigma\)-algebra is a \(\sigma\)-algebra generated by a topology. We will use \(\bor\) to denote the Borel \(\sigma\)-algebra of \(\RR\) that is generated by the usual open set topology.
\end{notation}

\begin{gap} This section needs to be continued with product spaces, the upper/lower continuity of measures, the construction of the Lebesgue measure, the Caratheodory theorem, and the Dynkin uniqueness theorem.\end{gap}

\section{Probability spaces}

\begin{definition}
Let \((\Omega, \col{f}, \p)\) be a measure space. If \(\p(\col{f}) = 1\), we call \(\p\) a \defname{probability measure}, we call \((\Omega, \col{f}, \p)\) a \defname{probability space}, and we call an element of \(\col{f}\) an \defname{event}.
\end{definition}

\begin{notation}
It is common to use a shorthand notation for events. We often write \(\{\text{condition}\}\) to mean \(\{\omega \in \Omega\;:\;\text{condition}\}\) and we often write \(\p(\text{condition})\) to mean \(\p\left(\{\omega \in \Omega\;:\;\text{condition}\}\right)\).
\end{notation}

\begin{definition}
If \((A_i)_{i \in \NN}\) are a sequence of events, ``\(A_i\) occurring \defname{infinitely often}'' is the event
\[\{A_i \text{ i.o.}\} = \bigcap_{m \in \NN} \;\bigcup_{n \geq m} A_n\]
and ``\(A_i\) occurring \defname{eventually}'' is the event
\[\{A_i \text{ eventually}\} = \bigcup_{m \in \NN} \;\bigcap_{n \geq m} A_n.\]
\end{definition}

\begin{remark}
\(\{A_i \text{ i.o.}\}\) is the set of elements \(\omega \in \Omega\) that belong in infinitely many of the events \((A_i)\) and \(\{A_i \text{ eventually}\}\) is the set of elements \(\omega \in \Omega\) that belong in all \((A_i)\) after a certain point. We note that \(\{A_i \text{ eventually}\} \subset \{A_i \text{ i.o.}\}\).
\end{remark}

\begin{definition}
The \defname{characteristic function} of an event \(A\) in \(\Omega\) is the function \(\charf{A}:\Omega \to \{0, 1\}\) that has \(\charf{A}(t) = 1\) if \(t \in A\) and \(\charf{A}(t) = 0\) if \(t \not\in A\).
\end{definition}

\begin{theorem}
Let \((A_i)_{i \in \NN}\) be a sequence of events.
\begin{enumerate}
\item
\(\charf{\{A_i \text{ i.o.}\}} = \limsup_{i \to \infty} \charf{A_i}\).
\item
\(\charf{\{A_i \text{ eventually}\}} = \liminf_{i \to \infty} \charf{A_i}\).
\end{enumerate}
\end{theorem}

\begin{proof}\ 
\begin{enumerate}
\item
Suppose \(\charf{\{A_i \text{ i.o.}\}}(t) = 1\). Then \(t \in \{A_i \text{ i.o.}\}\), so \(t\) is in infinitely many \(A_i\); call these \(A_{\alpha_i}\). Then \(\charf{A_{\alpha_i}}(t) = 1\) for all \(i\), so \(\lim_{i \to \infty} \charf{A_{\alpha_i}}(t) = 1\) and therefore \(\limsup_{i \to \infty} \charf{A_{i}}(t) = 1\).

Now suppose instead \(\limsup_{i \to \infty} \charf{A_{i}}(t) = 1\). Then there exists a subsequence \(\{A_{\alpha_i}\}\) and an \(N \in \NN\) so that \(\left|\charf{A_{\alpha_i}}(t) - 1 \right| < \frac{1}{2}\) for all \(i \geq N\). Then for these \(i\) it must be that  \(\charf{A_{\alpha_i}}(t) = 1\) so \(t \in A_{\alpha_i}\). Thus \(t\) is in infinitely many \(A_i\) so \(t \in \{A_i \text{ i.o.}\}\) and \(\charf{\{A_i \text{ i.o.}\}}(t) = 1\).

\item
Suppose \(\charf{\{A_i \text{ eventually}\}}(t) = 1\). Then \(t \in \{A_i \text{ eventually}\}\), so there exists an \(N \in \NN\) such that \(t\) is in all \(A_i\) for \(i \geq N\). For these \(i\) we have \(\charf{A_i}(t)=1\), so \(\lim_{i \to \infty} \charf{A_i}(t) = 1\). In particular \(\liminf_{i \to \infty} \charf{A_i}(t) = 1\).

Now suppose instead \(\liminf_{i \to \infty} \charf{A_i}(t) = 1\). Then there is no subsequence \(\{A_{\alpha_i}\}\) of \(\{A_i\}\) with \(\lim_{i \to \infty}\{A_{\alpha_i}\}(t) =0\), so there are finitely many \(A_i\) that do not contain \(t\). It follows that there exists an \(N \in \NN\) such that for all \(i \geq N\), \(t \in A_i\). Therefore \(t \in \{A_i \text{ eventually}\}\) and \(\charf{\{A_i \text{ eventually}\}}(t) = 1\).
\end{enumerate}
\end{proof}

\begin{gap}
The above proof could probably be shortened.
\end{gap}



\begin{gap} Add the Borel-Cantelli Lemma here.\end{gap}

\begin{definition}
Let \((\Omega, \col{f}, \p)\) be a probability space. Events \((A_i)_{i \in I} \in \col{f}\) are called \defname{independent} if for any finite \(J \subset I\) we have \(\p\left(\cap_{j \in J} A_j\right) = \prod_{j \in J} \p\left(A_j\right)\).
\end{definition}

\begin{theorem}
If \((A_n)\) are independent and for all \(n\) we define either \(B_n = A_n\) or \(B_n = A_n^C\) then all \((B_n)\) are independent.
\end{theorem}

\begin{gap}
Prove the above theorem.
\end{gap}

\begin{gap}
Add the Goldberg conjecture discussion here, as an example.
\end{gap}

\begin{definition}
Let \((\Omega, \col{f}, \p)\) be a probability space. Collections \((\col{A}_i) \subset \col{f}\) are called \defname{independent} if for any sequence \((A_i)\in\col{f}\) with \(A_i \in \col{A}_i\) the \((A_i)\) are independent.
\end{definition}

\section{Random variables}

\begin{definition}
Let \((\Omega_1, \col{f}_1, \mu_1)\) and \((\Omega_2, \col{f}_2, \mu_2)\) be measure spaces. A function \(g: \Omega_1 \to \Omega_2\) is called \defname{measurable} if for all \(A \in \col{f}_2\) we have \(g^{-1}(A) \in \col{f}_1\).
\end{definition}

\begin{remark}
This is similar to the topological definition of continuous functions.
\end{remark}


\begin{definition}
A \defname{random variable} on a probability space \((\Omega, \col{f}, \p)\) is a measurable function \(\rv{X}:\Omega \to \RR\), where we use the usual Borel \(\sigma\)-algebra as the \(\sigma\)-algebra on \(\RR\).
\end{definition}

\begin{notation}
When writing down an event involving a random variable \(\rv{X}\), it is common to write \(\rv{X}\) when we really mean \(\rv{X}(\omega)\). For example, we might write \(\p(\rv{X} = 1)\) to mean \(\p\left(\left\{\omega \in \Omega : \rv{X}(\omega) = 1\right\}\right)\).
\end{notation}


\begin{gap}
Add some examples of random variables.
\end{gap}

\begin{remark}
We can form an equivalence relation on random variables by writing \(\rv{X} \sim \rv{Y}\) if \(\p(X=Y)=1\), that is, if \(\{\omega \in \Omega : \rv{X}(\omega) \neq \rv{Y}(\omega)\}\) has measure zero. Equivalent random variables have the same probabilistic properties. Some may prefer to think of ``random variables'' as these equivalence classes of functions. In this sense, it doesn't make sense to ask what a random variable's value is for a certain \(\omega \in \Omega\); it only makes sense to look at the random variable's values on events with measure greater than zero.
\end{remark}

\begin{definition}
The \defname{distribution function} of a random variable \(\rv{X}\) is the function \(F_\rv{X}: \RR \to \RR\) given by \(F(t) = \p(X \leq t)\).
\end{definition}

We immediately see that distribution functions are monotonically increasing and right continuous (i.e., \(\lim_{t\to s^+} F_\rv{X}(t) = F_\rv{X}(s)\) for all \(s \in [0,1)\)). Also, \(F_\rv{X}\) has a jump discontinuity at \(s\) if and only if \(\p(\rv{X} = s) > 0\) (and if so, the jump is of size \(\p(\rv{X} = s)\)). There is an interesting theorem that provides something like a converse.

\begin{theorem}
Let \(F:\RR \to [0,1]\) be monotonically increasing and right continuous (i.e., \(\lim_{t\to s^+} F(t) = F(s)\) for all \(s \in [0,1))\). Then there exists a probability space \((\Omega, \col{f}, \p)\) and a random variable \(\rv{X}:\Omega \to \RR\) such that \(F = F_\rv{X}\).
\end{theorem}

\begin{gap}
Add the two theorem proofs.
\end{gap}

\begin{definition}
Given random variables \((\rv{X}_i)\) let \(\col{A}_i = \{{\rv{X}_i}^{-1}(A) : A \in \bor\}\). We say that \((\rv{X}_i)\) are \defname{independent} if \((\col{A}_i)\) are independent. (Here, \(\bor\) is the usual Borel \(\sigma\)-algebra on \(\RR\).)
\end{definition}

\begin{theorem}
Let \((\rv{X}_i)\) be random variables and let \(\col{A}_i = \left\{\left\{\rv{X}_i \leq t\right\} : t \in \RR\right\}\). Suppose \((\col{A}_i)\) are independent. Then \((\rv{X}_i)\) are independent.
\end{theorem}

\begin{gap}
Prove the theorem.
\end{gap}

\begin{definition}
The \defname{joint distribution function} of random variables \(\rv{X}_1, \ldots, \rv{X}_n\) is the function \(F:\RR^n \to \RR\) given by \[F\left(\langle t_1, \ldots, t_n\rangle\right) = \p \left(\rv{X}_i \leq t_i \;\forall\; i \in \{0, \ldots, n\}\right).\]
\end{definition}


\begin{gap}
Add notes on stochastic domination, percolation, etc.
\end{gap}









\end{document}
